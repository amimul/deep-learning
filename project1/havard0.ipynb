{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniproject 1\n",
    "Fingermovements predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "import numpy as np\n",
    "from math import log10\n",
    "\n",
    "# Our own code\n",
    "import helpers as HL\n",
    "import models as ML\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = HL.import_data(flatten=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new models if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model and define loss criterion and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(train_data[0][0])\n",
    "print(input_dim)\n",
    "output_dim = 1\n",
    "nb_hidden_layers = 2\n",
    "hidden_width = 300\n",
    "dropout_rate=0.3\n",
    "# initialize the model\n",
    "densemodel_1 = ML.DenseNet(input_dim, output_dim, nb_hidden_layers, hidden_width, dropout_rate)\n",
    "linear_model = ML.Linear_regression_model(input_dim, output_dim)\n",
    "\n",
    "model = densemodel_1\n",
    "# define loss criterion\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainsamples:  316\n",
      "Number of testsamples:  100\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.0301\n",
      "===> Prediction TRAIN-error: 0.5281\n",
      "===> Avg. PSNR: 0.2288 dB\n",
      "===> Prediction  TEST-error: 0.5268\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_0.pth -------------------------------------\n",
      "===> Epoch 10 Complete: Avg. Loss: 0.0137\n",
      "===> Prediction TRAIN-error: 0.2823\n",
      "===> Avg. PSNR: 0.3621 dB\n",
      "===> Prediction  TEST-error: 0.4554\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_10.pth -------------------------------------\n",
      "===> Epoch 20 Complete: Avg. Loss: 0.0136\n",
      "===> Prediction TRAIN-error: 0.2854\n",
      "===> Avg. PSNR: 0.4178 dB\n",
      "===> Prediction  TEST-error: 0.3661\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_20.pth -------------------------------------\n",
      "===> Epoch 30 Complete: Avg. Loss: 0.0067\n",
      "===> Prediction TRAIN-error: 0.1427\n",
      "===> Avg. PSNR: 0.4445 dB\n",
      "===> Prediction  TEST-error: 0.3393\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_30.pth -------------------------------------\n",
      "===> Epoch 40 Complete: Avg. Loss: 0.0049\n",
      "===> Prediction TRAIN-error: 0.1052\n",
      "===> Avg. PSNR: 0.4077 dB\n",
      "===> Prediction  TEST-error: 0.3750\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_40.pth -------------------------------------\n",
      "===> Epoch 50 Complete: Avg. Loss: 0.0027\n",
      "===> Prediction TRAIN-error: 0.0437\n",
      "===> Avg. PSNR: 0.4169 dB\n",
      "===> Prediction  TEST-error: 0.4018\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_50.pth -------------------------------------\n",
      "===> Epoch 60 Complete: Avg. Loss: 0.0030\n",
      "===> Prediction TRAIN-error: 0.0531\n",
      "===> Avg. PSNR: 0.4394 dB\n",
      "===> Prediction  TEST-error: 0.3393\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_60.pth -------------------------------------\n",
      "===> Epoch 70 Complete: Avg. Loss: 0.0017\n",
      "===> Prediction TRAIN-error: 0.0219\n",
      "===> Avg. PSNR: 0.4094 dB\n",
      "===> Prediction  TEST-error: 0.3929\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_70.pth -------------------------------------\n",
      "===> Epoch 80 Complete: Avg. Loss: 0.0023\n",
      "===> Prediction TRAIN-error: 0.0406\n",
      "===> Avg. PSNR: 0.3779 dB\n",
      "===> Prediction  TEST-error: 0.4107\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_80.pth -------------------------------------\n",
      "===> Epoch 90 Complete: Avg. Loss: 0.0031\n",
      "===> Prediction TRAIN-error: 0.0531\n",
      "===> Avg. PSNR: 0.3971 dB\n",
      "===> Prediction  TEST-error: 0.3661\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_90.pth -------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_model = HL.train_model(train_data, test_data, model, criterion, learning_rate=0.00005, epochs=100, batch_size=16, checkpoint_name='testingtesting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1400, out_features=300, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Dropout(p=0.3)\n",
      "  (5): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Dropout(p=0.3)\n",
      "  (8): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (9): ReLU()\n",
      "  (10): Dropout(p=0.3)\n",
      "  (11): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3)\n",
      "  (14): Linear(in_features=300, out_features=1, bias=True)\n",
      "  (15): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
